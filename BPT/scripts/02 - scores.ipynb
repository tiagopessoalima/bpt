{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d5a645c",
   "metadata": {},
   "source": [
    "# CONSTANTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8db7eb",
   "metadata": {},
   "source": [
    "**RANDOM_STATE** is a constant that is typically used to initialize the random number generator in a library or algorithm that uses randomness in some aspect of its operation. This means that when the RANDOM_STATE is fixed to a certain value, the algorithm will generate the same random results every time it is run, which can be useful for reproducing results and ensuring result consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b859eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6bdccf",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10fde4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from joblib import dump\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d962d51f",
   "metadata": {},
   "source": [
    "# READ FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d5412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training data from the CSV files\n",
    "X_train = pd.read_csv('../dataset/X_train.csv', usecols = ['TRACK', 'TRUST'])\n",
    "y_train = pd.read_csv('../dataset/y_train.csv', usecols = ['Blood Bags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d330a197",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d7fb88",
   "metadata": {},
   "source": [
    "## - Scores "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a189c62",
   "metadata": {},
   "source": [
    "Creates a machine learning pipeline that either scales input features and applies a given model or directly applies the given model\n",
    "- MinMaxScaler: works by subtracting the minimum value in the feature from each observation, and then dividing the result by the range (i.e., the maximum value minus the minimum value). This process ensures that the values in the feature are transformed to a range between 0 and 1.\n",
    "- BorderlineSMOTE: is an extension of the SMOTE algorithm, which is commonly used for addressing the class imbalance problem in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c1ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(model):\n",
    "    # Create a pipeline with preprocessing steps and a model\n",
    "    pipeline = make_pipeline(\n",
    "        MinMaxScaler(),  # Apply MinMaxScaler for feature scaling\n",
    "        BorderlineSMOTE(random_state=RANDOM_STATE),  # Apply BorderlineSMOTE for oversampling\n",
    "        model  # The specified model\n",
    "    )\n",
    "    \n",
    "    # Return the created pipeline\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da571b",
   "metadata": {},
   "source": [
    "We will explore two scores in this analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814169d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'TRACK': create_pipeline(LogisticRegression(random_state=RANDOM_STATE)),\n",
    "    'TRUST': create_pipeline(LogisticRegression(random_state=RANDOM_STATE))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5792a4",
   "metadata": {},
   "source": [
    "For logistic regression calibration, we define a search space for its hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9ef264",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'logisticregression__C': Real(1e-2,1e+2),\n",
    "    'logisticregression__max_iter' : Integer(100,1000),\n",
    "    'logisticregression__solver': Categorical(['newton-cg','lbfgs','liblinear','sag','saga']),\n",
    "    'logisticregression__fit_intercept': Categorical([True, False]),\n",
    "    'logisticregression__class_weight': Categorical(['balanced', None]),     \n",
    "    'logisticregression__l1_ratio': Real(0,1),\n",
    "    'borderlinesmote__sampling_strategy': Real(0.85,1.0),\n",
    "    'borderlinesmote__k_neighbors': Integer(1,10),\n",
    "    'borderlinesmote__m_neighbors': Integer(1,10)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfe269a",
   "metadata": {},
   "source": [
    "We instantiate a BayesSearchCV object that optimizes the hyperparameters of that specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c9433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store the optimized models\n",
    "opt = {}\n",
    "\n",
    "# Iterate over each item in the 'models' dictionary\n",
    "for model_name, model in models.items():\n",
    "    # Create a BayesSearchCV object for hyperparameter optimization\n",
    "    # using the specified model, search space, and other parameters\n",
    "    opt[model_name] = BayesSearchCV(\n",
    "        model,  # The model to optimize\n",
    "        space,  # The search space for hyperparameters\n",
    "        n_iter=10,  # Number of parameter settings that are sampled\n",
    "        cv=RepeatedStratifiedKFold(random_state=RANDOM_STATE),  # Cross-validation strategy\n",
    "        random_state=RANDOM_STATE,  # Random state for reproducibility\n",
    "        scoring='roc_auc'  # Scoring metric to optimize\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137d2161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each item in the 'opt' dictionary\n",
    "for model_name, model_opt in opt.items():\n",
    "    # Print the model name followed by a colon\n",
    "    print(model_name, end=': ')\n",
    "    \n",
    "    # Reshape the input data for the current model\n",
    "    X_train_model = X_train[model_name].values.reshape(-1, 1)\n",
    "        \n",
    "    # Fit the model using the selected features and the target variable\n",
    "    model_opt.fit(X_train_model, y_train)\n",
    "    \n",
    "    # Get the best score achieved by the model during cross-validation\n",
    "    best_score = model_opt.best_score_\n",
    "    \n",
    "    # Print the best score\n",
    "    print(best_score)\n",
    "    \n",
    "    # Generate the filename for saving the trained model\n",
    "    model_filename = '../models/scores/' + model_name + '.joblib'\n",
    "    \n",
    "    # Save the trained model to a file\n",
    "    dump(model_opt.best_estimator_, model_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
